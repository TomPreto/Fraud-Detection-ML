{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f35455b7",
   "metadata": {},
   "source": [
    "# DNN Assignment\n",
    "In this assignment you are working together with your teammates from the second project. You will apply your new knowledge about dense neural networks to the data from your ML project to investigate, if you can make further improvements on prediction performance. Your data is (hopefully) already cleaned and transformed (this was part of your ML project) such that you can focus fully on feeding it to your neural network. Use TensorFlow 2.x in this assignment as it makes training with real-life data much more easier with many implemented features (e.g. early-stopping, TensorBoard, regularization, etc.). \n",
    "\n",
    "In this notebook you will learn\n",
    "- how to apply a neural network to your own data using TensorFlow 2.x\n",
    "- how to tune the network and monitor learning\n",
    "- how to train several networks and ensemble them into a stronger model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f967c6d",
   "metadata": {},
   "source": [
    "# Module loading\n",
    "Load all the necessary packages for your assignment. We give you some modules in advance, feel free to add more, if you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e0d764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "    \n",
    "print('Using TensorFlow version: %s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b25ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs\n",
    "    \n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a12ef62",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "Load here your data from your ML project. You can use either `pandas` or `numpy` to format your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9eb56623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "dfc = pd.read_csv(\"/Users/linn/Desktop/neuefische/ds-artificial-neural-networks/data/client_train.csv\")\n",
    "dfi = pd.read_csv(\"/Users/linn/Desktop/neuefische/ds-artificial-neural-networks/data/ML_project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f74da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the values for certain columns and decider, wether we transform them to categorical or not.\n",
    "\n",
    "dfi.tarif_type= dfi.tarif_type.astype('category')\n",
    "dfi.counter_type = dfi.counter_type.astype('category')\n",
    "dfi.counter_code = dfi.counter_code.astype('category')\n",
    "dfi.reading_remarque = dfi.reading_remarque.astype('category')\n",
    "\n",
    "# some columns can be reduced to int8, 16 or 32 to save memory.\n",
    "dfi.counter_coefficient = dfi.counter_coefficient.astype('int8')\n",
    "\n",
    "dfi.months_number = dfi.months_number.astype('int16')\n",
    "\n",
    "dfi.consommation_level_4 = dfi.consommation_level_4.astype('int32')\n",
    "dfi.consommation_level_3 = dfi.consommation_level_3.astype('int32')\n",
    "dfi.consommation_level_2 = dfi.consommation_level_2.astype('int32')\n",
    "dfi.consommation_level_1 = dfi.consommation_level_1.astype('int32')\n",
    "\n",
    "# dfi.counter_statue.value_counts()\n",
    "dfi.counter_statue = dfi.counter_statue.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f4ab5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = dfi.query('avg_month_use > 100 ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7b6143b",
   "metadata": {},
   "source": [
    "Take care of the effects of the imbalanced dataset by downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3f7a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to drop counter number as well\n",
    "\n",
    "list_of_targets = dfc.query('target == 1').client_id.tolist()\n",
    "y = pd.Series(dfi.client_id.isin(list_of_targets))\n",
    "\n",
    "dfi['y'] = y\n",
    "\n",
    "n_positive = dfi.query('y == 1').shape[0]\n",
    "\n",
    "dfi_downsampled = dfi.query('y == 0').sample(n=n_positive)\n",
    "\n",
    "X = pd.concat([dfi_downsampled, dfi.query('y == 1')], axis=0)\n",
    "\n",
    "X.drop(['client_id', 'counter_number', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "y = X.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "174fde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target and feature (drop here the target and also get rid of the counter number)\n",
    "\n",
    "# X = dfi.drop(['client_id', 'counter_number', 'Unnamed: 0'], axis=1) #want to drop counter number as well\n",
    "\n",
    "# list_of_targets = dfc.query('target == 1').client_id.tolist()\n",
    "# y = pd.Series(dfi.client_id.isin(list_of_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6914971f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tarif_type', 'counter_statue', 'counter_code', 'reading_remarque',\n",
       "       'counter_coefficient', 'consommation_level_1', 'consommation_level_2',\n",
       "       'consommation_level_3', 'consommation_level_4', 'old_index',\n",
       "       'new_index', 'months_number', 'counter_type', 'avg_month_use'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features 'tarif_type' 'counter_code' 'reading_remarque' 'counter_statue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65da64cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tarif_type_8</th>\n",
       "      <th>tarif_type_9</th>\n",
       "      <th>tarif_type_10</th>\n",
       "      <th>tarif_type_11</th>\n",
       "      <th>tarif_type_12</th>\n",
       "      <th>tarif_type_13</th>\n",
       "      <th>tarif_type_14</th>\n",
       "      <th>tarif_type_15</th>\n",
       "      <th>tarif_type_18</th>\n",
       "      <th>tarif_type_21</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque_7</th>\n",
       "      <th>reading_remarque_8</th>\n",
       "      <th>reading_remarque_9</th>\n",
       "      <th>counter_statue_0</th>\n",
       "      <th>counter_statue_1</th>\n",
       "      <th>counter_statue_2</th>\n",
       "      <th>counter_statue_3</th>\n",
       "      <th>counter_statue_4</th>\n",
       "      <th>counter_statue_5</th>\n",
       "      <th>counter_statue_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358601</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124070</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094533</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548605</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tarif_type_8  tarif_type_9  tarif_type_10  tarif_type_11   \n",
       "358601              0             0              0              1  \\\n",
       "3124070             0             0              0              1   \n",
       "3094533             0             0              0              1   \n",
       "3548605             0             0              0              1   \n",
       "4312300             0             0              0              1   \n",
       "\n",
       "         tarif_type_12  tarif_type_13  tarif_type_14  tarif_type_15   \n",
       "358601               0              0              0              0  \\\n",
       "3124070              0              0              0              0   \n",
       "3094533              0              0              0              0   \n",
       "3548605              0              0              0              0   \n",
       "4312300              0              0              0              0   \n",
       "\n",
       "         tarif_type_18  tarif_type_21  ...  reading_remarque_7   \n",
       "358601               0              0  ...                   0  \\\n",
       "3124070              0              0  ...                   0   \n",
       "3094533              0              0  ...                   0   \n",
       "3548605              0              0  ...                   0   \n",
       "4312300              0              0  ...                   0   \n",
       "\n",
       "         reading_remarque_8  reading_remarque_9  counter_statue_0   \n",
       "358601                    0                   0                 1  \\\n",
       "3124070                   0                   0                 1   \n",
       "3094533                   0                   0                 1   \n",
       "3548605                   0                   0                 1   \n",
       "4312300                   0                   1                 1   \n",
       "\n",
       "         counter_statue_1  counter_statue_2  counter_statue_3   \n",
       "358601                  0                 0                 0  \\\n",
       "3124070                 0                 0                 0   \n",
       "3094533                 0                 0                 0   \n",
       "3548605                 0                 0                 0   \n",
       "4312300                 0                 0                 0   \n",
       "\n",
       "         counter_statue_4  counter_statue_5  counter_statue_6  \n",
       "358601                  0                 0                 0  \n",
       "3124070                 0                 0                 0  \n",
       "3094533                 0                 0                 0  \n",
       "3548605                 0                 0                 0  \n",
       "4312300                 0                 0                 0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummy variables for the categorical features\n",
    "cat_features = ['tarif_type', 'counter_code', 'reading_remarque', 'counter_statue']\n",
    "\n",
    "X_cat = pd.get_dummies(X[['tarif_type', 'counter_code', 'reading_remarque', 'counter_statue']], prefix= cat_features, prefix_sep='_', dtype='uint8')\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b152c088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>avg_month_use</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque_7</th>\n",
       "      <th>reading_remarque_8</th>\n",
       "      <th>reading_remarque_9</th>\n",
       "      <th>counter_statue_0</th>\n",
       "      <th>counter_statue_1</th>\n",
       "      <th>counter_statue_2</th>\n",
       "      <th>counter_statue_3</th>\n",
       "      <th>counter_statue_4</th>\n",
       "      <th>counter_statue_5</th>\n",
       "      <th>counter_statue_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358601</th>\n",
       "      <td>1</td>\n",
       "      <td>861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30919</td>\n",
       "      <td>31780</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>215.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124070</th>\n",
       "      <td>1</td>\n",
       "      <td>646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25300</td>\n",
       "      <td>25946</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>161.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094533</th>\n",
       "      <td>1</td>\n",
       "      <td>746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30446</td>\n",
       "      <td>31192</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>186.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548605</th>\n",
       "      <td>1</td>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11652</td>\n",
       "      <td>12515</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>215.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312300</th>\n",
       "      <td>1</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70913</td>\n",
       "      <td>71514</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>150.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         counter_coefficient  consommation_level_1  consommation_level_2   \n",
       "358601                     1                   861                     0  \\\n",
       "3124070                    1                   646                     0   \n",
       "3094533                    1                   746                     0   \n",
       "3548605                    1                   863                     0   \n",
       "4312300                    1                   601                     0   \n",
       "\n",
       "         consommation_level_3  consommation_level_4  old_index  new_index   \n",
       "358601                      0                     0      30919      31780  \\\n",
       "3124070                     0                     0      25300      25946   \n",
       "3094533                     0                     0      30446      31192   \n",
       "3548605                     0                     0      11652      12515   \n",
       "4312300                     0                     0      70913      71514   \n",
       "\n",
       "         months_number counter_type  avg_month_use  ...  reading_remarque_7   \n",
       "358601               4            0         215.25  ...                   0  \\\n",
       "3124070              4            0         161.50  ...                   0   \n",
       "3094533              4            0         186.50  ...                   0   \n",
       "3548605              4            0         215.75  ...                   0   \n",
       "4312300              4            0         150.25  ...                   0   \n",
       "\n",
       "         reading_remarque_8  reading_remarque_9  counter_statue_0   \n",
       "358601                    0                   0                 1  \\\n",
       "3124070                   0                   0                 1   \n",
       "3094533                   0                   0                 1   \n",
       "3548605                   0                   0                 1   \n",
       "4312300                   0                   1                 1   \n",
       "\n",
       "         counter_statue_1  counter_statue_2  counter_statue_3   \n",
       "358601                  0                 0                 0  \\\n",
       "3124070                 0                 0                 0   \n",
       "3094533                 0                 0                 0   \n",
       "3548605                 0                 0                 0   \n",
       "4312300                 0                 0                 0   \n",
       "\n",
       "         counter_statue_4  counter_statue_5  counter_statue_6  \n",
       "358601                  0                 0                 0  \n",
       "3124070                 0                 0                 0  \n",
       "3094533                 0                 0                 0  \n",
       "3548605                 0                 0                 0  \n",
       "4312300                 0                 0                 0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate both together \n",
    "\n",
    "X = pd.concat([X.drop(cat_features, axis = 1), X_cat], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c4544b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2b4b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical values\n",
    "col_scale = ['counter_coefficient', 'consommation_level_1', 'consommation_level_2', 'consommation_level_3', 'consommation_level_4', 'months_number', 'old_index', 'new_index', 'avg_month_use']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train[col_scale] = scaler.fit_transform(X_train[col_scale])\n",
    "X_test[col_scale] = scaler.transform(X_test[col_scale])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26098865",
   "metadata": {},
   "source": [
    "## Training\n",
    "For training you need a train/val split (hopefully you did a train/test split before (and you should use the same as in your ML project to make results comparable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06babcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train validation split  by splitting furtherthe X_train data\n",
    " # do not do it like this! The fit function has a validation split\n",
    "\n",
    "# X_train_train = X_train.sample(frac=0.8, random_state=42)\n",
    "# X_train_val = X_train.drop(X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "467c0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_VAL = len()\n",
    "N_TRAIN = len(X_train)\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "EPOCHS = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afda48b9",
   "metadata": {},
   "source": [
    "### Build, compile and fit your model\n",
    "To become fast at retraining your (different) models it is good practice to define a function that gets fed by a model, its name, an optimizer to use and the number of epochs you want the model to be trained. \n",
    "\n",
    "If your model trains for many epochs you will receive a lot of logging from TensorFlow. To reduce the logging noise you can use a callback (provided by the `tensorflow_docs` module we installed and imported for you) named `EpochDots()` that simply prints a `.` for each epoch and a full set of metrics after a number of epochs have been trained. \n",
    "\n",
    "If you want to produce logs for using TensorBoard you also need to include the `callbacks.TensorBoard()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing previous logs\n",
    "!rm -rf my_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f12ecdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50955111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for new directory \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c171cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for creating a new folder for each run\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%d_%m_%Y-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "747d5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce0a2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the callbacks function\n",
    "def get_callbacks(name):\n",
    "    return tf.keras.callbacks.TensorBoard(run_logdir+name, histogram_freq=1)\n",
    "\n",
    "# return [list of your callbacks]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abfcdd8a",
   "metadata": {},
   "source": [
    "You can implement your callbacks in the `model.fit()` method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f042f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compile_and_fit(model, optimizer=None ,verbose=0):\n",
    "    # Get optimizer\n",
    "    # model.compile\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mae',\n",
    "                  metrics=['mse'])\n",
    "    # model.fit\n",
    "    model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=verbose,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS)\n",
    "    return model\n",
    "    \n",
    "    # return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b436f486",
   "metadata": {},
   "source": [
    "#### Build your model\n",
    "You can build your model by using `tf.keras.Sequential()` that helps you to sequentially define your different layers from input to output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "535bfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your_model = tf.keras.Sequential([\n",
    "#    layers.Dense(),\n",
    "#    layers.Dense()\n",
    "#])    \n",
    "\n",
    "Bane_of_frauds = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(32,kernel_initializer = 'uniform', activation='relu', input_dim = 79),\n",
    "      tf.keras.layers.Dense(32,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c31056e5",
   "metadata": {},
   "source": [
    "#### Train your model\n",
    "Train your model by using your `model_compile_and_fit()` function you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0df56c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 24s 778ms/step - loss: 859.8848 - mse: 1173132.1250 - val_loss: 408.8295 - val_mse: 195839.7656\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 24s 797ms/step - loss: 319.7281 - mse: 162003.1719 - val_loss: 271.1839 - val_mse: 86024.1562\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 22s 744ms/step - loss: 214.4667 - mse: 88363.5547 - val_loss: 162.1869 - val_mse: 30749.4395\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 24s 796ms/step - loss: 217.7237 - mse: 88266.7656 - val_loss: 196.5713 - val_mse: 45306.1016\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 24s 814ms/step - loss: 210.8453 - mse: 87295.7578 - val_loss: 192.3194 - val_mse: 43249.3242\n"
     ]
    }
   ],
   "source": [
    "# Model 1 was run with N_train = 1000 and only 5 epochs\n",
    "optimizer_model = tf.optimizers.Adam(learning_rate= 0.1)\n",
    "your_history = model_compile_and_fit(Bane_of_frauds, optimizer = optimizer_model, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ff494c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "312/312 [==============================] - 26s 83ms/step - loss: 330.4006 - mse: 233269.4375 - val_loss: 142.9357 - val_mse: 23894.4785\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 25s 81ms/step - loss: 300.0847 - mse: 174839.1406 - val_loss: 305.2665 - val_mse: 109067.0938\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 26s 83ms/step - loss: 350.5782 - mse: 181033.9219 - val_loss: 24.4779 - val_mse: 698.2937\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 25s 80ms/step - loss: 294.9922 - mse: 147976.0469 - val_loss: 213.3633 - val_mse: 53322.5781\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 26s 83ms/step - loss: 342.4513 - mse: 169848.5312 - val_loss: 5.9814 - val_mse: 41.6683\n"
     ]
    }
   ],
   "source": [
    "# Model 2 was run with N_train = 10000 and only 5 epochs\n",
    "optimizer_model = tf.optimizers.Adam(learning_rate= 0.1)\n",
    "your_history = model_compile_and_fit(Bane_of_frauds, optimizer = optimizer_model, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "208aedec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "312/312 [==============================] - 26s 82ms/step - loss: 11.1855 - mse: 252.2151 - val_loss: 1.4810 - val_mse: 4.4714\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 25s 80ms/step - loss: 4.6224 - mse: 34.2591 - val_loss: 2.9694 - val_mse: 9.1430\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 25s 80ms/step - loss: 3.4819 - mse: 13.4244 - val_loss: 4.8004 - val_mse: 23.8278\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 25s 79ms/step - loss: 3.3469 - mse: 13.2352 - val_loss: 3.3402 - val_mse: 11.7080\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 24s 77ms/step - loss: 3.2806 - mse: 11.6271 - val_loss: 2.5840 - val_mse: 7.0082\n"
     ]
    }
   ],
   "source": [
    "# Model 3 was run with now dummy variables for the cat features and N_train = 10000 and only 5 epochs\n",
    "optimizer_model = tf.optimizers.Adam(learning_rate= 0.1)\n",
    "your_history = model_compile_and_fit(Bane_of_frauds, optimizer = optimizer_model, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f247cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7060/7060 [==============================] - 42s 6ms/step - loss: 14.6466 - mse: 363.7617 - val_loss: 2.3552 - val_mse: 5.8498\n",
      "Epoch 2/200\n",
      "7060/7060 [==============================] - 36s 5ms/step - loss: 14.8148 - mse: 370.4562 - val_loss: 5.9949 - val_mse: 36.4533\n",
      "Epoch 3/200\n",
      "7060/7060 [==============================] - 36s 5ms/step - loss: 15.8403 - mse: 425.7485 - val_loss: 9.6269 - val_mse: 93.2448\n",
      "Epoch 4/200\n",
      "7060/7060 [==============================] - 36s 5ms/step - loss: 14.9496 - mse: 386.9802 - val_loss: 8.4243 - val_mse: 72.6720\n",
      "Epoch 5/200\n",
      "5649/7060 [=======================>......] - ETA: 6s - loss: 14.8083 - mse: 363.0542"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Model 4 was run with now dummy variables for the cat features a balanced dataset (len of double of only y=1 entries) with N_train = len(X_train) epochs = 200\u001b[39;00m\n\u001b[1;32m      2\u001b[0m optimizer_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m your_history \u001b[39m=\u001b[39m model_compile_and_fit(Bane_of_frauds, optimizer \u001b[39m=\u001b[39;49m optimizer_model, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m, in \u001b[0;36mmodel_compile_and_fit\u001b[0;34m(model, optimizer, max_epochs, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m      5\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[39m# model.fit\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[1;32m      9\u001b[0m                     y_train,\n\u001b[1;32m     10\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m                     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     12\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49mSTEPS_PER_EPOCH,\n\u001b[1;32m     13\u001b[0m                     epochs\u001b[39m=\u001b[39;49mEPOCHS)\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/neuefische/ds-artificial-neural-networks/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 4 was run with now dummy variables for the cat features a balanced dataset (len of double of only y=1 entries) with N_train = len(X_train) epochs = 200\n",
    "optimizer_model = tf.optimizers.Adam(learning_rate= 0.1)\n",
    "your_history = model_compile_and_fit(Bane_of_frauds, optimizer = optimizer_model, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74a0e282",
   "metadata": {},
   "source": [
    "#### Evaluate your model training\n",
    "TensorFlow offers now (this was more cumbersome before) a simple history plotter that you can use to plot training histories and see how the model performed on training and validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model 3 \n",
    "history_plotter = tfdocs.plots.HistoryPlotter(metric = 'your_metric', smoothing_std=10)\n",
    "history_plotter.plot(your_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85938cce",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "You might have no luck with your first model (most surely you did not). In this section you will apply methods you know to tune your model's performance. An obvious way of course is to change your model's architecture (removing or adding layers or layer dimensions, changing activation functions). \n",
    "\n",
    "However, after this you might still be able to detect some overfitting and there are some more methods you can apply to improve your neural network. Some of them are regularization, learning rate decay, early stopping, or dropout. \n",
    "\n",
    "If you want to add regularization you can apply directly layer-wise L2- or L1-regularization by using a layer's `kernel_regularization` argument and an appropriate regularizer from the [`tensorflow.keras.regularizers`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers) module we imported for you.  \n",
    "\n",
    "__Optimizer schedules__<br>\n",
    "Quite often your optimizer does not run efficiently through the loss function surface. Remember that theory ensures a convergence of mini-batch SGD if and only if the learing rate decreases sufficiently fast. A way to apply this to your model training is to use a learning rate scheduler (learning rate decay) that reduces the learning rate over the number of update steps. The [`tf.keras.optimizers.schedules`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules) module offers you some approaches to do that. \n",
    "\n",
    "Note that to apply this to your `model_compile_and_fit()` function you defined above you need to implement the learning rate schedule either in there or with a helper function that your function calls inside. \n",
    "\n",
    "If you want to visualize different schedulers you can define them and call them on a range of values and plot them in a line plot. \n",
    "\n",
    "__Early stopping__<br>\n",
    "Earyl stopping is a procedure that enables you to stop your training earlier than defined by your `max_epochs` argument. It is used in practices to \n",
    "1. determine the optimal parameter vector by monitoring the validation error closely (if it rises again too much stuck with the best parameters found until then) and\n",
    "2. to save expensive resources (either in terms of monetary costs or ecological costs).\n",
    "\n",
    "To implement early stopping in TensorFlow the `tf.keras` module offers you a `callback` named [`tf.keras.callback.EarlyStopping()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) that monitors for you a certain metric (it makes sense here to use a validation metric) and to stop training after a certain number of epochs with no improvement or by defining a certain `min_delta` that defines a minimum value of improvement - if below the callback stops your training. \n",
    "\n",
    "You can add this callback simply to the callbacks defined in your `get_callbacks()` function you defined above.\n",
    "\n",
    "__Dropout__<br>\n",
    "Dropout was one of the important developments in regularization for neural networks. It was developed by Geoffrey Hinton and his team at Toronto University. \n",
    "\n",
    "Dropout can be applied to each layer in your network and is implemented in `tf.keras` by an own layer named `Dropout()` awaiting a dropout rate set by you. So to introduce dropout you have to rework your model design.  \n",
    "\n",
    "Make use of your knowledge and apply tuning techniques to improve your network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3acc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========#\n",
    "# YOUR CODE #\n",
    "#===========#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25560d3a",
   "metadata": {},
   "source": [
    "## Model ensembling\n",
    "You have learned that models can be ensembled. What is possible in `scikit-learn` is also possible in TensorFlow, just a little different as it is relying on its computation graph. However, any model is callable like a `layer` by invoking it on either an `Input` or on the output of another layer. Furthermore, you can also stack outputs together.\n",
    "\n",
    "To produce an ensemble you can define a couple of models, than use their predictions as inputs for another model and produce a final output (using `keras.Model(input, output)`). But you can also start simple and use the mean predictions over all models and then compute the `argmax()` to assign them to a class in classification (via using `layers.average([model1_preds,model2_preds,...])`). You will be surprised how well this works. \n",
    "\n",
    "Now implement your own ensemble to improve your work even a little more and to have something more to polish up your ML project on `GitHub` ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========#\n",
    "# YOUR CODE #\n",
    "#===========#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
